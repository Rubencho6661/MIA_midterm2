{
  "hash": "8e20a1b073b310d7b0722456d6ac0e2f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"EVALUACION MIDTERM - Modelamiento de balance de masa\"\nauthor: \"Ruben Basantes\" \ndate: \"2025-10-04\"\nformat:\n  html:\n    embed-resources: true\nexecute:\n  kernel: \"Python (.venv)\"\n---\n\n## ¿Qué es la regresión lineal simple?\n\nEs un método estadístico que se enfoca en analizar la relación lineal entre dos variables:\n\n- Una **variable independiente** X (por ejemplo: horas de estudio)\n- Una **variable dependiente** Y \n\nEl modelo tiene esta forma:\n\nY = b0 + b1*X\n\nDonde:\n\n- b0: es la **intersección (intercepto)**. Es el valor de Y cuando X = 0.  \n- b1: es la **pendiente de la recta**, y representa cuánto cambia Y por cada unidad que aumenta X.\n\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos, es decir que \nexista una minima diferencia entre el valor real y lo predicho. Este es el criterio de **mínimos cuadrados**.\n\n## 0. Importando librerias\nSe importan las librerias desde los paquetes\n\n::: {#7a46c472 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport seaborn as sns\n```\n:::\n\n\n## 1. Carga y exploración inicial del dataset.\nSe cargan los datos del archivo .csv, que proviene de una cobertura de puntos en formato shapefile.La tabla contiene atributos asociados a los balanves de masa.\n\n::: {#6508dafc .cell execution_count=2}\n``` {.python .cell-code}\ndf = gpd.read_file(\"ant_20222016_Dh_adjslp_pts.dbf\")\n# Ver primeras filas\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VALUE</th>\n      <th>Este</th>\n      <th>Norte</th>\n      <th>asp1</th>\n      <th>rgh1</th>\n      <th>slp1</th>\n      <th>tpi1</th>\n      <th>tri1</th>\n      <th>elev1</th>\n      <th>prec1</th>\n      <th>tmed1</th>\n      <th>dhdt</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.083925</td>\n      <td>816872.728</td>\n      <td>9947471.064</td>\n      <td>0.109970</td>\n      <td>1.692383</td>\n      <td>20.886478</td>\n      <td>-0.075195</td>\n      <td>1.031517</td>\n      <td>4861.926758</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.847321</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.190065</td>\n      <td>816876.728</td>\n      <td>9947471.064</td>\n      <td>350.337708</td>\n      <td>1.587891</td>\n      <td>20.204298</td>\n      <td>-0.185059</td>\n      <td>0.905296</td>\n      <td>4861.905273</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.698344</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.812052</td>\n      <td>816880.728</td>\n      <td>9947471.064</td>\n      <td>343.757568</td>\n      <td>1.791992</td>\n      <td>19.912228</td>\n      <td>-0.005859</td>\n      <td>0.305124</td>\n      <td>4862.399414</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.635342</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.402457</td>\n      <td>816884.728</td>\n      <td>9947471.064</td>\n      <td>335.548126</td>\n      <td>1.941406</td>\n      <td>20.086668</td>\n      <td>-0.081055</td>\n      <td>0.596693</td>\n      <td>4862.826172</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.567076</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.139728</td>\n      <td>816888.728</td>\n      <td>9947471.064</td>\n      <td>346.701843</td>\n      <td>1.399414</td>\n      <td>16.271687</td>\n      <td>0.032715</td>\n      <td>0.829091</td>\n      <td>4863.404297</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.523288</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nSe identifican las variables con valores faltantes y se visualizan en un gráfico de barras.\nsto permite decidir si imputar valores o eliminar registros incompletos.\n\n::: {#1466c794 .cell execution_count=3}\n``` {.python .cell-code}\n# Porcentaje de valores faltantes por columna\nnan_percent = df.isna().mean() * 100\nnan_percent_sorted = nan_percent.sort_values(ascending=False).round(2)\n\nprint(\"Porcentaje de valores faltantes por columna:\")\nprint(nan_percent_sorted)\n\n# === Visualización opcional con gráfico de barras ===\nnan_percent_sorted[nan_percent_sorted > 0].plot(\n    kind='barh', color='salmon', figsize=(8,5)\n)\nplt.title(\"Porcentaje de valores faltantes por variable\")\nplt.xlabel(\"Porcentaje (%)\")\nplt.ylabel(\"Variable\")\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPorcentaje de valores faltantes por columna:\ngeometry    100.00\ntri1          0.05\nasp1          0.03\nrgh1          0.03\nslp1          0.03\ntpi1          0.03\nVALUE         0.00\nEste          0.00\nNorte         0.00\nelev1         0.00\nprec1         0.00\ntmed1         0.00\ndhdt          0.00\ndtype: float64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](midterm_files/figure-html/cell-4-output-2.png){width=707 height=449}\n:::\n:::\n\n\nLa seleccion de seleccion de variables considera:\nVALUE: variable dependiente (0 = sin deslizamiento, 1 = con deslizamiento)\nfeatures: variables explicativas derivadas del terreno o clima\nSe eliminan filas con valores faltantes.\n\n::: {#92565257 .cell execution_count=4}\n``` {.python .cell-code}\n# La tercera columna ('desliz_occ') es la variable dependiente (0 = no, 1 = sí)\ntarget_col = 'dhdt'\n\n# Seleccion de variables explicativas numéricas\n# Excluimos 'slp1','tri1', 'elev1'\n# Puedes ajustar según tus columnas reales\nfeatures = [\n    'asp1', 'rgh1',  \n    'tpi1', 'prec1', #'tmed1',\n]\n\n# Eliminacion filas con NaN\ndf_clean = df.dropna(subset=features + [target_col])\ndf_clean\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VALUE</th>\n      <th>Este</th>\n      <th>Norte</th>\n      <th>asp1</th>\n      <th>rgh1</th>\n      <th>slp1</th>\n      <th>tpi1</th>\n      <th>tri1</th>\n      <th>elev1</th>\n      <th>prec1</th>\n      <th>tmed1</th>\n      <th>dhdt</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.083925</td>\n      <td>816872.728</td>\n      <td>9947471.064</td>\n      <td>0.109970</td>\n      <td>1.692383</td>\n      <td>20.886478</td>\n      <td>-0.075195</td>\n      <td>1.031517</td>\n      <td>4861.926758</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.847321</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.190065</td>\n      <td>816876.728</td>\n      <td>9947471.064</td>\n      <td>350.337708</td>\n      <td>1.587891</td>\n      <td>20.204298</td>\n      <td>-0.185059</td>\n      <td>0.905296</td>\n      <td>4861.905273</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.698344</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.812052</td>\n      <td>816880.728</td>\n      <td>9947471.064</td>\n      <td>343.757568</td>\n      <td>1.791992</td>\n      <td>19.912228</td>\n      <td>-0.005859</td>\n      <td>0.305124</td>\n      <td>4862.399414</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.635342</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.402457</td>\n      <td>816884.728</td>\n      <td>9947471.064</td>\n      <td>335.548126</td>\n      <td>1.941406</td>\n      <td>20.086668</td>\n      <td>-0.081055</td>\n      <td>0.596693</td>\n      <td>4862.826172</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.567076</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.139728</td>\n      <td>816888.728</td>\n      <td>9947471.064</td>\n      <td>346.701843</td>\n      <td>1.399414</td>\n      <td>16.271687</td>\n      <td>0.032715</td>\n      <td>0.829091</td>\n      <td>4863.404297</td>\n      <td>1597.466675</td>\n      <td>4</td>\n      <td>0.523288</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12744</th>\n      <td>3.653540</td>\n      <td>818000.728</td>\n      <td>9946483.064</td>\n      <td>286.290894</td>\n      <td>1.176758</td>\n      <td>12.845374</td>\n      <td>-0.012207</td>\n      <td>0.600953</td>\n      <td>5676.818359</td>\n      <td>1620.902954</td>\n      <td>1</td>\n      <td>0.608923</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12745</th>\n      <td>2.058196</td>\n      <td>818004.728</td>\n      <td>9946483.064</td>\n      <td>313.943970</td>\n      <td>0.792969</td>\n      <td>8.523555</td>\n      <td>0.015137</td>\n      <td>0.545106</td>\n      <td>5677.481445</td>\n      <td>1620.902954</td>\n      <td>1</td>\n      <td>0.343033</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12746</th>\n      <td>3.595429</td>\n      <td>817996.728</td>\n      <td>9946479.064</td>\n      <td>325.155609</td>\n      <td>1.776367</td>\n      <td>18.057718</td>\n      <td>-0.006348</td>\n      <td>0.829797</td>\n      <td>5676.610352</td>\n      <td>1620.902954</td>\n      <td>1</td>\n      <td>0.599238</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12747</th>\n      <td>3.493276</td>\n      <td>818000.728</td>\n      <td>9946479.064</td>\n      <td>312.475830</td>\n      <td>1.260742</td>\n      <td>12.594838</td>\n      <td>0.014160</td>\n      <td>0.402667</td>\n      <td>5677.309570</td>\n      <td>1620.902954</td>\n      <td>1</td>\n      <td>0.582213</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>12748</th>\n      <td>2.510170</td>\n      <td>818004.728</td>\n      <td>9946479.064</td>\n      <td>308.570496</td>\n      <td>1.098633</td>\n      <td>10.395593</td>\n      <td>0.020508</td>\n      <td>0.225643</td>\n      <td>5677.936523</td>\n      <td>1620.902954</td>\n      <td>1</td>\n      <td>0.418362</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>12745 rows × 13 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#868d9a61 .cell execution_count=5}\n``` {.python .cell-code}\n# Crear subconjunto de datos\nX = df_clean[features]\ny = df_clean[target_col].astype(float)\n# Verificar valores faltantes\nX.info()\nX.describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 12745 entries, 0 to 12748\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   asp1    12745 non-null  float64\n 1   rgh1    12745 non-null  float64\n 2   tpi1    12745 non-null  float64\n 3   prec1   12745 non-null  float64\ndtypes: float64(4)\nmemory usage: 497.9 KB\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>asp1</th>\n      <th>rgh1</th>\n      <th>tpi1</th>\n      <th>prec1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12745.000000</td>\n      <td>12745.000000</td>\n      <td>12745.000000</td>\n      <td>12745.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>302.222725</td>\n      <td>3.209007</td>\n      <td>-0.002589</td>\n      <td>1607.246096</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>48.370283</td>\n      <td>1.380399</td>\n      <td>0.230966</td>\n      <td>5.351926</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.007507</td>\n      <td>0.428711</td>\n      <td>-7.901855</td>\n      <td>1597.466675</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>291.430939</td>\n      <td>2.405273</td>\n      <td>-0.048340</td>\n      <td>1602.755249</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>311.032043</td>\n      <td>2.984375</td>\n      <td>0.001465</td>\n      <td>1606.763550</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>326.036591</td>\n      <td>3.654297</td>\n      <td>0.047852</td>\n      <td>1610.514771</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>359.985260</td>\n      <td>26.353516</td>\n      <td>8.570801</td>\n      <td>1620.902954</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLa matriz de correlacion permite identificar colinealidad entre variables explicativas.\nValores altos (>0.8 o <−0.8) pueden indicar redundancia entre variables.\n\n::: {#1a195b6b .cell execution_count=6}\n``` {.python .cell-code}\n# --- Asegurar que solo se usen variables numéricas ---\ncorrelation_matrix = X.corr()\nprint(correlation_matrix)\n\n# Visualizar matriz de correlación\nplt.figure(figsize=(7, 5))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Matriz de Correlación de los predictores')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           asp1      rgh1      tpi1     prec1\nasp1   1.000000 -0.089663 -0.015036 -0.047092\nrgh1  -0.089663  1.000000 -0.074002  0.333880\ntpi1  -0.015036 -0.074002  1.000000 -0.017936\nprec1 -0.047092  0.333880 -0.017936  1.000000\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](midterm_files/figure-html/cell-7-output-2.png){width=553 height=432}\n:::\n:::\n\n\n## 2. División en conjuntos de entrenamiento y prueba (train_test_split).\nSe dividen los datos:\n - 80% para entrenar el modelo\n - 20% para evaluar su desempeño\n\n::: {#eabeeaa1 .cell execution_count=7}\n``` {.python .cell-code}\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\nprint(\"Tamaño entrenamiento:\", X_train.shape)\nprint(\"Tamaño prueba:\", X_test.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTamaño entrenamiento: (8921, 4)\nTamaño prueba: (3824, 4)\n```\n:::\n:::\n\n\n## 3. Definición y entrenamiento del modelo utilizando Pipeline.\nEtapas del pipeline:\n\n - Imputer: reemplaza valores faltantes por la media.\n - Scaler: estandariza las variables (media = 0, desviación = 1).\n - Regresión logística: modelo lineal que estima la probabilidad de deslizamiento.\n - class_weight='balanced': ajusta el peso de las clases para evitar sesgo hacia la clase mayoritaria.\n\n::: {#9a46311a .cell execution_count=8}\n``` {.python .cell-code}\n# Definir pipeline: estandarización + regresión logística\n#pipe = Pipeline([\n#    ('imputer', SimpleImputer(strategy='mean')),  # or 'median'\n#    ('scaler', StandardScaler()),\n#    ('logreg', LogisticRegression(solver='liblinear', class_weight='balanced',max_iter=1000))\n#])\n\npipe = Pipeline([\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n    (\"scaler\", StandardScaler()),\n    (\"regressor\", LinearRegression())\n])\n\n# Entrenar modelo\npipe.fit(X_train, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures(include_bias=False)),\n                (&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;regressor&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;poly&#x27;, PolynomialFeatures(include_bias=False)),\n                (&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;regressor&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>\n```\n:::\n:::\n\n\n## 4. Generación de predicciones.\n\n::: {#35e0f21f .cell execution_count=9}\n``` {.python .cell-code}\ny_pred = pipe.predict(X_test)\ny_pred[:5]\n#y_prob = pipe.predict_proba(X_test)[:, 1]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([-0.04770735,  0.13927089,  0.21075155,  0.07770748, -0.09311675])\n```\n:::\n:::\n\n\n## 5. Evaluación del modelo con métricas apropiadas.\n\n::: {#e7ba1f5c .cell execution_count=10}\n``` {.python .cell-code}\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n```\n:::\n\n\nEl *Mean Squared Error (MSE)* mide cuánto se desvían en promedio las predicciones de los valores reales. Un MSE de 0.22 significa que el error cuadrático medio entre los valores reales del balance de masa y los predichos por el modelo es aproximadamente 0.22 metros, siendo muy alto y poco eficiente. Entonces el modelo no está logrando capturar bien la relación entre las variables explicativas y la variable dependiente. \n\n::: {#9acc5e60 .cell execution_count=11}\n``` {.python .cell-code}\nprint(\"Mean Squared Error (MSE):\", mse)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error (MSE): 0.22894841340348443\n```\n:::\n:::\n\n\nEl *R²* mide la proporción de la variabilidad de la variable objetivo que logra explicar el modelo. Un R² = 0.14 india que el modelo solo explica aproximadamente el 14% de la variación de los datos. Asi, las variables explicativas actuales (aspecto, pendiente, elevación, rugosidad, etc.) no son suficientes para explicar el comportamiento del balance de masa.\n\n::: {#943bd79a .cell execution_count=12}\n``` {.python .cell-code}\nprint(\"R² Score:\", r2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR² Score: 0.11863329007754908\n```\n:::\n:::\n\n\n## 6. Visualizaciones e interpretación de resultados.\nEn la matriz de comfusion\nDiagonal principal → predicciones correctas.\nFuera de la diagonal → errores del modelo.\n\n::: {#59fa4820 .cell execution_count=13}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,6))\nplt.scatter(y_test, y_pred, alpha=0.7)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\nplt.xlabel(\"Valores Reales\")\nplt.ylabel(\"Valores Predichos\")\nplt.title(\"Regresión Lineal: Valores Reales vs Predichos\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](midterm_files/figure-html/cell-14-output-1.png){width=662 height=524}\n:::\n:::\n\n\n",
    "supporting": [
      "midterm_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}