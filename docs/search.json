[
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "",
    "text": "Es un método estadístico que se enfoca en analizar la relación lineal entre dos variables:\n\nUna variable independiente X (por ejemplo: horas de estudio)\nUna variable dependiente Y\n\nEl modelo tiene esta forma:\nY = b0 + b1*X\nDonde:\n\nb0: es la intersección (intercepto). Es el valor de Y cuando X = 0.\n\nb1: es la pendiente de la recta, y representa cuánto cambia Y por cada unidad que aumenta X.\n\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos, es decir que exista una minima diferencia entre el valor real y lo predicho. Este es el criterio de mínimos cuadrados."
  },
  {
    "objectID": "midterm.html#qué-es-la-regresión-lineal-simple",
    "href": "midterm.html#qué-es-la-regresión-lineal-simple",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "",
    "text": "Es un método estadístico que se enfoca en analizar la relación lineal entre dos variables:\n\nUna variable independiente X (por ejemplo: horas de estudio)\nUna variable dependiente Y\n\nEl modelo tiene esta forma:\nY = b0 + b1*X\nDonde:\n\nb0: es la intersección (intercepto). Es el valor de Y cuando X = 0.\n\nb1: es la pendiente de la recta, y representa cuánto cambia Y por cada unidad que aumenta X.\n\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos, es decir que exista una minima diferencia entre el valor real y lo predicho. Este es el criterio de mínimos cuadrados."
  },
  {
    "objectID": "midterm.html#importando-librerias",
    "href": "midterm.html#importando-librerias",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "0. Importando librerias",
    "text": "0. Importando librerias\nSe importan las librerias desde los paquetes\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport seaborn as sns"
  },
  {
    "objectID": "midterm.html#carga-y-exploración-inicial-del-dataset.",
    "href": "midterm.html#carga-y-exploración-inicial-del-dataset.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "1. Carga y exploración inicial del dataset.",
    "text": "1. Carga y exploración inicial del dataset.\nSe cargan los datos del archivo .csv, que proviene de una cobertura de puntos en formato shapefile.La tabla contiene atributos asociados a los balanves de masa.\n\n\nCode\ndf = gpd.read_file(\"ant_20222016_Dh_adjslp_pts.dbf\")\n# Ver primeras filas\ndf.head()\n\n\n\n\n\n\n\n\n\nVALUE\nEste\nNorte\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\nprec1\ntmed1\ndhdt\ngeometry\n\n\n\n\n0\n5.083925\n816872.728\n9947471.064\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n1597.466675\n4\n0.847321\nNone\n\n\n1\n4.190065\n816876.728\n9947471.064\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n1597.466675\n4\n0.698344\nNone\n\n\n2\n3.812052\n816880.728\n9947471.064\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n1597.466675\n4\n0.635342\nNone\n\n\n3\n3.402457\n816884.728\n9947471.064\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n1597.466675\n4\n0.567076\nNone\n\n\n4\n3.139728\n816888.728\n9947471.064\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n1597.466675\n4\n0.523288\nNone\n\n\n\n\n\n\n\nSe identifican las variables con valores faltantes y se visualizan en un gráfico de barras. sto permite decidir si imputar valores o eliminar registros incompletos.\n\n\nCode\n# Porcentaje de valores faltantes por columna\nnan_percent = df.isna().mean() * 100\nnan_percent_sorted = nan_percent.sort_values(ascending=False).round(2)\n\nprint(\"Porcentaje de valores faltantes por columna:\")\nprint(nan_percent_sorted)\n\n# === Visualización opcional con gráfico de barras ===\nnan_percent_sorted[nan_percent_sorted &gt; 0].plot(\n    kind='barh', color='salmon', figsize=(8,5)\n)\nplt.title(\"Porcentaje de valores faltantes por variable\")\nplt.xlabel(\"Porcentaje (%)\")\nplt.ylabel(\"Variable\")\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.show()\n\n\nPorcentaje de valores faltantes por columna:\ngeometry    100.00\ntri1          0.05\nasp1          0.03\nrgh1          0.03\nslp1          0.03\ntpi1          0.03\nVALUE         0.00\nEste          0.00\nNorte         0.00\nelev1         0.00\nprec1         0.00\ntmed1         0.00\ndhdt          0.00\ndtype: float64\n\n\n\n\n\n\n\n\n\nLa seleccion de seleccion de variables considera: VALUE: variable dependiente (0 = sin deslizamiento, 1 = con deslizamiento) features: variables explicativas derivadas del terreno o clima Se eliminan filas con valores faltantes.\n\n\nCode\n# La tercera columna ('desliz_occ') es la variable dependiente (0 = no, 1 = sí)\ntarget_col = 'dhdt'\n\n# Seleccion de variables explicativas numéricas\n# Excluimos 'slp1','tri1', 'elev1'\n# Puedes ajustar según tus columnas reales\nfeatures = [\n    'asp1', 'rgh1',  \n    'tpi1', 'prec1', #'tmed1',\n]\n\n# Eliminacion filas con NaN\ndf_clean = df.dropna(subset=features + [target_col])\ndf_clean\n\n\n\n\n\n\n\n\n\nVALUE\nEste\nNorte\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\nprec1\ntmed1\ndhdt\ngeometry\n\n\n\n\n0\n5.083925\n816872.728\n9947471.064\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n1597.466675\n4\n0.847321\nNone\n\n\n1\n4.190065\n816876.728\n9947471.064\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n1597.466675\n4\n0.698344\nNone\n\n\n2\n3.812052\n816880.728\n9947471.064\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n1597.466675\n4\n0.635342\nNone\n\n\n3\n3.402457\n816884.728\n9947471.064\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n1597.466675\n4\n0.567076\nNone\n\n\n4\n3.139728\n816888.728\n9947471.064\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n1597.466675\n4\n0.523288\nNone\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n12744\n3.653540\n818000.728\n9946483.064\n286.290894\n1.176758\n12.845374\n-0.012207\n0.600953\n5676.818359\n1620.902954\n1\n0.608923\nNone\n\n\n12745\n2.058196\n818004.728\n9946483.064\n313.943970\n0.792969\n8.523555\n0.015137\n0.545106\n5677.481445\n1620.902954\n1\n0.343033\nNone\n\n\n12746\n3.595429\n817996.728\n9946479.064\n325.155609\n1.776367\n18.057718\n-0.006348\n0.829797\n5676.610352\n1620.902954\n1\n0.599238\nNone\n\n\n12747\n3.493276\n818000.728\n9946479.064\n312.475830\n1.260742\n12.594838\n0.014160\n0.402667\n5677.309570\n1620.902954\n1\n0.582213\nNone\n\n\n12748\n2.510170\n818004.728\n9946479.064\n308.570496\n1.098633\n10.395593\n0.020508\n0.225643\n5677.936523\n1620.902954\n1\n0.418362\nNone\n\n\n\n\n12745 rows × 13 columns\n\n\n\n\n\nCode\n# Crear subconjunto de datos\nX = df_clean[features]\ny = df_clean[target_col].astype(float)\n# Verificar valores faltantes\nX.info()\nX.describe()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 12745 entries, 0 to 12748\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   asp1    12745 non-null  float64\n 1   rgh1    12745 non-null  float64\n 2   tpi1    12745 non-null  float64\n 3   prec1   12745 non-null  float64\ndtypes: float64(4)\nmemory usage: 497.9 KB\n\n\n\n\n\n\n\n\n\nasp1\nrgh1\ntpi1\nprec1\n\n\n\n\ncount\n12745.000000\n12745.000000\n12745.000000\n12745.000000\n\n\nmean\n302.222725\n3.209007\n-0.002589\n1607.246096\n\n\nstd\n48.370283\n1.380399\n0.230966\n5.351926\n\n\nmin\n0.007507\n0.428711\n-7.901855\n1597.466675\n\n\n25%\n291.430939\n2.405273\n-0.048340\n1602.755249\n\n\n50%\n311.032043\n2.984375\n0.001465\n1606.763550\n\n\n75%\n326.036591\n3.654297\n0.047852\n1610.514771\n\n\nmax\n359.985260\n26.353516\n8.570801\n1620.902954\n\n\n\n\n\n\n\nLa matriz de correlacion permite identificar colinealidad entre variables explicativas. Valores altos (&gt;0.8 o &lt;−0.8) pueden indicar redundancia entre variables.\n\n\nCode\n# --- Asegurar que solo se usen variables numéricas ---\ncorrelation_matrix = X.corr()\nprint(correlation_matrix)\n\n# Visualizar matriz de correlación\nplt.figure(figsize=(7, 5))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Matriz de Correlación de los predictores')\nplt.show()\n\n\n           asp1      rgh1      tpi1     prec1\nasp1   1.000000 -0.089663 -0.015036 -0.047092\nrgh1  -0.089663  1.000000 -0.074002  0.333880\ntpi1  -0.015036 -0.074002  1.000000 -0.017936\nprec1 -0.047092  0.333880 -0.017936  1.000000"
  },
  {
    "objectID": "midterm.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "href": "midterm.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "2. División en conjuntos de entrenamiento y prueba (train_test_split).",
    "text": "2. División en conjuntos de entrenamiento y prueba (train_test_split).\nSe dividen los datos: - 80% para entrenar el modelo - 20% para evaluar su desempeño\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\n\nprint(\"Tamaño entrenamiento:\", X_train.shape)\nprint(\"Tamaño prueba:\", X_test.shape)\n\n\nTamaño entrenamiento: (8921, 4)\nTamaño prueba: (3824, 4)"
  },
  {
    "objectID": "midterm.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "href": "midterm.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "3. Definición y entrenamiento del modelo utilizando Pipeline.",
    "text": "3. Definición y entrenamiento del modelo utilizando Pipeline.\nEtapas del pipeline:\n\nImputer: reemplaza valores faltantes por la media.\nScaler: estandariza las variables (media = 0, desviación = 1).\nRegresión logística: modelo lineal que estima la probabilidad de deslizamiento.\nclass_weight=‘balanced’: ajusta el peso de las clases para evitar sesgo hacia la clase mayoritaria.\n\n\n\nCode\n# Definir pipeline: estandarización + regresión logística\n#pipe = Pipeline([\n#    ('imputer', SimpleImputer(strategy='mean')),  # or 'median'\n#    ('scaler', StandardScaler()),\n#    ('logreg', LogisticRegression(solver='liblinear', class_weight='balanced',max_iter=1000))\n#])\n\npipe = Pipeline([\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n    (\"scaler\", StandardScaler()),\n    (\"regressor\", LinearRegression())\n])\n\n# Entrenar modelo\npipe.fit(X_train, y_train)\n\n\nPipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n                ('scaler', StandardScaler()),\n                ('regressor', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n                ('scaler', StandardScaler()),\n                ('regressor', LinearRegression())])PolynomialFeaturesPolynomialFeatures(include_bias=False)StandardScalerStandardScaler()LinearRegressionLinearRegression()"
  },
  {
    "objectID": "midterm.html#generación-de-predicciones.",
    "href": "midterm.html#generación-de-predicciones.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "4. Generación de predicciones.",
    "text": "4. Generación de predicciones.\n\n\nCode\ny_pred = pipe.predict(X_test)\ny_pred[:5]\n#y_prob = pipe.predict_proba(X_test)[:, 1]\n\n\narray([-0.04770735,  0.13927089,  0.21075155,  0.07770748, -0.09311675])"
  },
  {
    "objectID": "midterm.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "href": "midterm.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "5. Evaluación del modelo con métricas apropiadas.",
    "text": "5. Evaluación del modelo con métricas apropiadas.\n\n\nCode\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n\nEl Mean Squared Error (MSE) mide cuánto se desvían en promedio las predicciones de los valores reales. Un MSE de 0.22 significa que el error cuadrático medio entre los valores reales del balance de masa y los predichos por el modelo es aproximadamente 0.22 metros, siendo muy alto y poco eficiente. Entonces el modelo no está logrando capturar bien la relación entre las variables explicativas y la variable dependiente.\n\n\nCode\nprint(\"Mean Squared Error (MSE):\", mse)\n\n\nMean Squared Error (MSE): 0.22894841340348443\n\n\nEl R² mide la proporción de la variabilidad de la variable objetivo que logra explicar el modelo. Un R² = 0.14 india que el modelo solo explica aproximadamente el 14% de la variación de los datos. Asi, las variables explicativas actuales (aspecto, pendiente, elevación, rugosidad, etc.) no son suficientes para explicar el comportamiento del balance de masa.\n\n\nCode\nprint(\"R² Score:\", r2)\n\n\nR² Score: 0.11863329007754908"
  },
  {
    "objectID": "midterm.html#visualizaciones-e-interpretación-de-resultados.",
    "href": "midterm.html#visualizaciones-e-interpretación-de-resultados.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "6. Visualizaciones e interpretación de resultados.",
    "text": "6. Visualizaciones e interpretación de resultados.\nEn la matriz de comfusion Diagonal principal → predicciones correctas. Fuera de la diagonal → errores del modelo.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,6))\nplt.scatter(y_test, y_pred, alpha=0.7)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\nplt.xlabel(\"Valores Reales\")\nplt.ylabel(\"Valores Predichos\")\nplt.title(\"Regresión Lineal: Valores Reales vs Predichos\")\nplt.show()"
  },
  {
    "objectID": "Ejercicio/ant_20222016_Dh_adjslp_pts.html",
    "href": "Ejercicio/ant_20222016_Dh_adjslp_pts.html",
    "title": "Machine Learning",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  },
  {
    "objectID": "Ejercicio/point_samples.html",
    "href": "Ejercicio/point_samples.html",
    "title": "Machine Learning",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  }
]