[
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html",
    "title": "Aprendizaje Supervisado",
    "section": "",
    "text": "Autor: Manuel Eugenio Morocho Cayamcela, PhD"
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#regresión-lineal-simple---cálculo-e-interpretación-paso-a-paso",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#regresión-lineal-simple---cálculo-e-interpretación-paso-a-paso",
    "title": "Aprendizaje Supervisado",
    "section": "Regresión Lineal Simple - Cálculo e Interpretación Paso a Paso",
    "text": "Regresión Lineal Simple - Cálculo e Interpretación Paso a Paso"
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#qué-es-la-regresión-lineal-simple",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#qué-es-la-regresión-lineal-simple",
    "title": "Aprendizaje Supervisado",
    "section": "¿Qué es la regresión lineal simple?",
    "text": "¿Qué es la regresión lineal simple?\nEs un método estadístico que nos permite encontrar una relación lineal entre dos variables:\n\nUna variable independiente $ X $ (por ejemplo: horas de estudio)\nUna variable dependiente $ Y $ (por ejemplo: nota en el examen)\n\nEl modelo tiene esta forma:\n$ Y = _0 + _1 X $\nDonde:\n\n$ _0 $: es la intersección (intercepto). Es el valor de $ Y $ cuando $ X = 0 $.\n\n$ _1 $: es la pendiente de la recta, y representa cuánto cambia $ Y $ por cada unidad que aumenta $ X $."
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#de-dónde-salen-las-fórmulas",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#de-dónde-salen-las-fórmulas",
    "title": "Aprendizaje Supervisado",
    "section": "¿De dónde salen las fórmulas?",
    "text": "¿De dónde salen las fórmulas?\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos. Esa recta tiene la forma:\n$ _i = _0 + _1 x_i $\nDonde $ _i $ es el valor predicho, y $ y_i $ el valor real observado.\n\n¿Qué significa “mejor ajuste”?\nQueremos que los errores entre lo real y lo predicho sean lo más pequeños posible:\n$ _i = y_i - _i = y_i - (_0 + _1 x_i) $\nPara evitar que los errores se cancelen (positivos con negativos), los elevamos al cuadrado. Así, minimizamos el siguiente error total:\n$ = _{i=1}^{n} (y_i - _0 - _1 x_i)^2 $\nEste es el criterio de mínimos cuadrados.\n\n\n¿Cómo se minimiza?\nUsamos cálculo: derivamos la función de error respecto a los parámetros y resolvemos:\n\nDerivada respecto a $ _0 $:\n\n$ (y_i - _0 - _1 x_i)^2 = 0 $\n\nDerivada respecto a $ _1 $:\n\n$ (y_i - _0 - _1 x_i)^2 = 0 $\nEstas dos ecuaciones (llamadas ecuaciones normales) se resuelven para obtener:\n$ _1 = $ $ _0 = {y} - _1 {x} $"
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#paso-a-paso-con-un-ejemplo-numérico",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#paso-a-paso-con-un-ejemplo-numérico",
    "title": "Aprendizaje Supervisado",
    "section": "Paso a Paso con un Ejemplo Numérico",
    "text": "Paso a Paso con un Ejemplo Numérico\n\nDatos\n\n\n\nX (Horas de estudio)\nY (Nota)\n\n\n\n\n1\n3\n\n\n2\n5\n\n\n3\n7\n\n\n\n\n\nCalcular los promedios\n$ {X} = = 2 $ $ {Y} = = 5 $\n\n\nCalcular la pendiente $ _1 $\n$ _1 = $\n\n\n\n\n\n\n\n\n\n\n\nX\nY\n\\(X - \\bar{X}\\)\n\\(Y - \\bar{Y}\\)\n\\((X - \\bar{X})(Y - \\bar{Y})\\)\n\\((X - \\bar{X})^2\\)\n\n\n\n\n1\n3\n-1\n-2\n2\n1\n\n\n2\n5\n0\n0\n0\n0\n\n\n3\n7\n1\n2\n2\n1\n\n\n\n$ _1 = = = 2 $\n\n\nCalcular el intercepto $ _0 $\n$ _0 = {Y} - _1 {X} = 5 - 2 = 1 $\n\n\nEcuación final de la recta\n$ Y = 1 + 2X $"
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#interpretación",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#interpretación",
    "title": "Aprendizaje Supervisado",
    "section": "Interpretación",
    "text": "Interpretación\n\n**Intercepto $ _0 = 1 $**: si no estudias nada (X = 0), la predicción de tu nota es 1.\n**Pendiente $ _1 = 2 $: por cada hora adicional de estudio, se espera que la nota aumente en 2 puntos**.\n\n\n\nCode\n## Visualización con Python\nimport matplotlib.pyplot as plt\n\n# Datos\nX = [1, 2, 3]\nY = [3, 5, 7]\n\n# Coeficientes calculados\nbeta_0 = 1\nbeta_1 = 2\n\n# Recta de regresión\nX_line = [0, 4]\nY_line = [beta_0 + beta_1 * x for x in X_line]\n\n# Gráfico\nplt.figure(figsize=(8, 5))\nplt.scatter(X, Y, color='blue', label='Datos')\nplt.plot(X_line, Y_line, color='red', linestyle='--', label='Línea de regresión')\nplt.xlabel('Horas de estudio (X)')\nplt.ylabel('Nota obtenida (Y)')\nplt.title('Regresión Lineal Simple')\nplt.legend()\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#predicción-de-gastos-médicos-para-una-aseguradora-usando-regresión-lineal-múltiple",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#predicción-de-gastos-médicos-para-una-aseguradora-usando-regresión-lineal-múltiple",
    "title": "Aprendizaje Supervisado",
    "section": "Predicción de Gastos Médicos para una Aseguradora usando Regresión Lineal Múltiple",
    "text": "Predicción de Gastos Médicos para una Aseguradora usando Regresión Lineal Múltiple\n\nIntroducción:\nEn esta actividad, exploraremos el concepto de regresión lineal utilizando la base de datos insurance.csv. La regresión lineal es una técnica de aprendizaje supervisado que se utiliza para predecir el valor de una variable dependiente (en este caso, charges, basada en una o más variables independientes (por ejemplo, age, bmi, children, etc.).\nPuedes descargar la base de datos desde acá.\n\n\n\nimage.png\n\n\nLa base de datos insurance.csv contiene información sobre individuos y sus cargos médicos. A continuación se describe cada una de las variables presentes en el archivo:\n\nage: Edad del individuo (en años).\nsex: Sexo del individuo (male para masculino y female para femenino).\nbmi: Índice de Masa Corporal (IMC) del individuo, una medida del peso en relación con la altura.\nchildren: Número de hijos o dependientes que tiene el individuo.\nsmoker: Indica si el individuo es fumador (yes para sí y no para no).\nregion: Región geográfica en la que reside el individuo (northeast, northwest, southeast, southwest).\ncharges: Cargos médicos totales facturados al individuo (en dólares).\n\nEstas variables se utilizan comúnmente para analizar y predecir los costos médicos en función de las características demográficas y de salud de los individuos.\n\n\nContenido:\n\nImportamos los paquetes necesarios\n\n\nCode\n# Instalamos los paquetes necesarios\n%pip install scikit-learn # Paquete de machine learning con algoritmos de clasificación, regresión, clustering, etc.\n%pip install pandas\n%pip install matplotlib\n%pip install seaborn\n\n# Importamos los paquetes necesarios\nfrom sklearn.linear_model import LinearRegression # Regresión lineal con scikit-learn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\nERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n    #\n    ^\n\n\nRequirement already satisfied: pandas in d:\\maestria_ai\\.venv\\lib\\site-packages (2.3.2)\nRequirement already satisfied: numpy&gt;=1.23.2 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas) (2.1.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\maestria_ai\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: matplotlib in d:\\maestria_ai\\.venv\\lib\\site-packages (3.10.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (4.59.2)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: numpy&gt;=1.23 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (2.1.3)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow&gt;=8 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\nRequirement already satisfied: python-dateutil&gt;=2.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six&gt;=1.5 in d:\\maestria_ai\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: seaborn in d:\\maestria_ai\\.venv\\lib\\site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,&gt;=1.20 in d:\\maestria_ai\\.venv\\lib\\site-packages (from seaborn) (2.1.3)\nRequirement already satisfied: pandas&gt;=1.2 in d:\\maestria_ai\\.venv\\lib\\site-packages (from seaborn) (2.3.2)\nRequirement already satisfied: matplotlib!=3.6.1,&gt;=3.4 in d:\\maestria_ai\\.venv\\lib\\site-packages (from seaborn) (3.10.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.3.3)\nRequirement already satisfied: cycler&gt;=0.10 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (4.59.2)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.4.9)\nRequirement already satisfied: packaging&gt;=20.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (25.0)\nRequirement already satisfied: pillow&gt;=8 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (11.3.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (3.2.3)\nRequirement already satisfied: python-dateutil&gt;=2.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas&gt;=1.2-&gt;seaborn) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\maestria_ai\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\nCargamos la base de datos\n\n\nCode\n# Cargamos la base de datos 'insurance.csv'\ninsurance = pd.read_csv('D:/Maestria_AI/Actividad 6/insurance.csv')\n\n# Visualizamos las primeras 10 filas de la base de datos cargada\ninsurance.head(10)\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n5\n31\nfemale\n25.740\n0\nno\nsoutheast\n3756.62160\n\n\n6\n46\nfemale\n33.440\n1\nno\nsoutheast\n8240.58960\n\n\n7\n37\nfemale\n27.740\n3\nno\nnorthwest\n7281.50560\n\n\n8\n37\nmale\n29.830\n2\nno\nnortheast\n6406.41070\n\n\n9\n60\nfemale\n25.840\n0\nno\nnorthwest\n28923.13692\n\n\n\n\n\n\n\n\n\nCode\n# Imprimimos los valores únicos de 'region' \ninsurance['region'].unique()\n\n\narray(['southwest', 'southeast', 'northwest', 'northeast'], dtype=object)\n\n\n\n\nPreprocesamiento de datos\n\n\nCode\n# Codificamos las variables categóricas 'sex' y 'smoker' con un reemplazo de etiquetas (label encoding)\ninsurance['sex'] = insurance['sex'].replace({'female': 0, 'male': 1})\ninsurance['smoker'] = insurance['smoker'].replace({'no': 0, 'yes': 1})\n\n#Codificamos la variable 'region' y eliminamos la primera columna (one-hot encoding)\ninsurance = pd.get_dummies(insurance, columns=['region'], dtype=int)\n\n# Visualizamos las primeras 10 filas después del preprocesamiento\ninsurance.head(10)\n\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18208\\1607253937.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  insurance['sex'] = insurance['sex'].replace({'female': 0, 'male': 1})\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18208\\1607253937.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  insurance['smoker'] = insurance['smoker'].replace({'no': 0, 'yes': 1})\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\ncharges\nregion_northeast\nregion_northwest\nregion_southeast\nregion_southwest\n\n\n\n\n0\n19\n0\n27.900\n0\n1\n16884.92400\n0\n0\n0\n1\n\n\n1\n18\n1\n33.770\n1\n0\n1725.55230\n0\n0\n1\n0\n\n\n2\n28\n1\n33.000\n3\n0\n4449.46200\n0\n0\n1\n0\n\n\n3\n33\n1\n22.705\n0\n0\n21984.47061\n0\n1\n0\n0\n\n\n4\n32\n1\n28.880\n0\n0\n3866.85520\n0\n1\n0\n0\n\n\n5\n31\n0\n25.740\n0\n0\n3756.62160\n0\n0\n1\n0\n\n\n6\n46\n0\n33.440\n1\n0\n8240.58960\n0\n0\n1\n0\n\n\n7\n37\n0\n27.740\n3\n0\n7281.50560\n0\n1\n0\n0\n\n\n8\n37\n1\n29.830\n2\n0\n6406.41070\n1\n0\n0\n0\n\n\n9\n60\n0\n25.840\n0\n0\n28923.13692\n0\n1\n0\n0\n\n\n\n\n\n\n\n\n\nPreparamos las variables X y y\n\n\nCode\n# Seleccionamos las variable independiente (X)\nX = insurance.drop('charges', axis=1)\nX\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion_northeast\nregion_northwest\nregion_southeast\nregion_southwest\n\n\n\n\n0\n19\n0\n27.900\n0\n1\n0\n0\n0\n1\n\n\n1\n18\n1\n33.770\n1\n0\n0\n0\n1\n0\n\n\n2\n28\n1\n33.000\n3\n0\n0\n0\n1\n0\n\n\n3\n33\n1\n22.705\n0\n0\n0\n1\n0\n0\n\n\n4\n32\n1\n28.880\n0\n0\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1333\n50\n1\n30.970\n3\n0\n0\n1\n0\n0\n\n\n1334\n18\n0\n31.920\n0\n0\n1\n0\n0\n0\n\n\n1335\n18\n0\n36.850\n0\n0\n0\n0\n1\n0\n\n\n1336\n21\n0\n25.800\n0\n0\n0\n0\n0\n1\n\n\n1337\n61\n0\n29.070\n0\n1\n0\n1\n0\n0\n\n\n\n\n1338 rows × 9 columns\n\n\n\n\n\nCode\n# Seleccionamos la variable dependiente (y)\ny = insurance['charges']\ny\n\n\n0       16884.92400\n1        1725.55230\n2        4449.46200\n3       21984.47061\n4        3866.85520\n           ...     \n1333    10600.54830\n1334     2205.98080\n1335     1629.83350\n1336     2007.94500\n1337    29141.36030\nName: charges, Length: 1338, dtype: float64\n\n\n\n\nDividimos los datos en conjuntos de entrenamiento y prueba\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n\n\n\nInstanciamos un modelo de Regresión Lineal y lo ajustamos con los valores de X_train y y_train\n\n\nCode\n# Creamos una instancia del modelo de regresión lineal\nmodelo_regresion = LinearRegression()\n\n# Ajustamos el modelo a los datos de entrenamiento\nmodelo_regresion.fit(X_train, y_train)\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\n\n(Opcional) Guardamos el modelo en formato .pkl\nEl formato .pkl es una extensión de archivo utilizada para almacenar objetos serializados en Python mediante el módulo pickle. Este módulo permite convertir objetos de Python en una secuencia de bytes, lo que facilita su almacenamiento en archivos o su transmisión a través de redes. Los archivos .pkl son comúnmente utilizados para guardar modelos entrenados en aprendizaje automático, estructuras de datos complejas, o cualquier otro objeto que necesite ser persistido entre sesiones de ejecución de un programa. La deserialización de estos archivos permite restaurar los objetos a su estado original, manteniendo su estructura y datos intactos.\n\n\nCode\n# Guardamos el modelo para usarlo en el futuro\nimport joblib\njoblib.dump(modelo_regresion, 'modelo_regresion.pkl')\n\n\n['modelo_regresion.pkl']\n\n\n\n\n(Opcional) Cargamos el modelo en formato .pkl\n\n\nCode\n# Cargamos el modelo guardado\nmodelo_regresion = joblib.load('modelo_regresion.pkl')\n\n\n\n\n\nObtenemos los coeficientes y el intercepto del modelo de regresión\nEn el contexto de la regresión lineal, los coeficientes y el intercepto son parámetros fundamentales que definen la relación entre las variables independientes (predictoras) y la variable dependiente (respuesta).\n\na) Coeficientes\nLos coeficientes (también conocidos como pesos o betas) representan la magnitud y la dirección de la relación entre cada variable independiente y la variable dependiente. En una ecuación de regresión lineal múltiple, cada coeficiente indica cuánto cambia la variable dependiente cuando la variable independiente correspondiente aumenta en una unidad, manteniendo constantes las demás variables independientes. Matemáticamente, si tenemos una ecuación de regresión lineal de la forma:\n\\(y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n\\)\ndonde: - \\(y\\) es la variable dependiente (objetivo). - \\(\\beta_0\\) es el intercepto. - $_1, _2, , _n $ son los coeficientes de las variables independientes \\(X_1, X_2, \\ldots, X_n\\).\n\n\nb) Intercepto\nEl intercepto \\(\\beta_0\\) es el valor de la variable dependiente cuando todas las variables independientes son iguales a cero. Representa el punto donde la recta de regresión cruza el eje \\(y\\). En otras palabras, es el valor predicho de \\(y\\) cuando no hay influencia de las variables independientes.\n\n\nEjemplo:\nSi tenemos una ecuación de regresión lineal simple con dos variables independientes, podría verse así:\n\\(y = 3 + 2X_1 - 4X_2\\)\nEn este caso: - El intercepto \\(\\beta_0\\) es 3. - El coeficiente de \\(X_1\\) (\\(\\beta_1\\)) es 2, lo que significa que por cada incremento de una unidad en \\(X_1\\), \\(y\\) aumenta en 2 unidades. - El coeficiente de \\(X_2\\) (\\(\\beta_2\\)) es -4, lo que significa que por cada incremento de una unidad en \\(X_2\\), \\(y\\) disminuye en 4 unidades.\nEstos parámetros son esenciales para interpretar el modelo de regresión lineal y entender cómo las variables independientes afectan la variable dependiente.\n\n\nCode\n# Obtenemos los coeficientes \ncoeficientes = modelo_regresion.coef_\ncoeficientes\n\n\narray([  259.27991344,  -137.29729888,   336.01728964,   430.16955009,\n       23869.12582694,   358.80134028,   220.53293786,  -316.76882105,\n        -262.56545709])\n\n\n\n\nCode\n# Obtenemos el intercepto \nintercepto = modelo_regresion.intercept_\nintercepto\n\n\nnp.float64(-12530.75779220644)\n\n\n\n\nCode\n# Definimos la ecuación de la recta de regresión\necuacion_recta = 'y = ' + ' + '.join([f'{coeficientes[i]}*X{i}' for i in range(len(coeficientes))]) + f' + {intercepto}'\nprint(f'Ecuación de la recta de regresión: {ecuacion_recta}')\n\n\nEcuación de la recta de regresión: y = 259.27991344090975*X0 + -137.29729888138658*X1 + 336.0172896390925*X2 + 430.16955009264126*X3 + 23869.12582694413*X4 + 358.8013402815794*X5 + 220.532937855384*X6 + -316.7688210493754*X7 + -262.5654570875852*X8 + -12530.75779220644\n\n\nCon la ecuación de la recta de regresión, podemos realizar predicciones sobre los cargos médicos basándonos en las características de entrada. Esta ecuación nos permite entender cómo cada característica influye en el resultado final, proporcionando una relación matemática clara entre las variables independientes (características) y la variable dependiente (cargos médicos). Al aplicar esta ecuación a nuevos datos, podemos estimar los cargos médicos esperados, lo cual es útil para análisis predictivos, toma de decisiones informadas y planificación de recursos en el ámbito de la salud. Además, la ecuación de la recta de regresión facilita la interpretación de los coeficientes, ayudándonos a identificar qué factores tienen mayor impacto en los costos médicos.\nCon los datos de los coeficientes encontrados en la ecuación de la recta de regresión, podemos analizar la influencia de cada variable independiente en los costos médicos. Los coeficientes representan el cambio esperado en la variable dependiente (cargos médicos) por cada unidad de cambio en la variable independiente correspondiente, manteniendo constantes las demás variables.\nPara determinar qué variables tienen mayor impacto en los costos médicos, podemos observar los valores absolutos de los coeficientes:\n\nCoeficientes más altos: Indican que la variable asociada tiene un mayor impacto en los costos médicos. Un coeficiente alto significa que un pequeño cambio en esta variable resultará en un cambio significativo en los costos médicos.\nCoeficientes más bajos: Indican que la variable asociada tiene un menor impacto en los costos médicos. Un coeficiente bajo significa que un cambio en esta variable resultará en un cambio menor en los costos médicos.\n\nAdemás, el signo del coeficiente (positivo o negativo) nos indica la dirección de la relación entre la variable independiente y los costos médicos:\n\nCoeficiente positivo: Un aumento en la variable independiente está asociado con un aumento en los costos médicos.\nCoeficiente negativo: Un aumento en la variable independiente está asociado con una disminución en los costos médicos.\n\nAnalizando estos coeficientes, podemos identificar cuáles son las variables más influyentes y cómo afectan los costos médicos, lo que puede ser útil para la toma de decisiones y la planificación en el ámbito de la salud.\n\n\nCode\n# Crear un DataFrame para facilitar la interpretación\ncoef_df = pd.DataFrame({'Variable': X.columns, 'Coeficiente': coeficientes})\n\n# Ordenar por el valor absoluto del coeficiente para ver cuáles son más importantes\ncoef_df['Abs_Coeficiente'] = coef_df['Coeficiente'].abs()\n\n# Ordenamos los coeficientes de mayor a menor\ncoef_df = coef_df.sort_values(by='Abs_Coeficiente', ascending=False)\n\nprint(coef_df)\n\n\n           Variable   Coeficiente  Abs_Coeficiente\n4            smoker  23869.125827     23869.125827\n3          children    430.169550       430.169550\n5  region_northeast    358.801340       358.801340\n2               bmi    336.017290       336.017290\n7  region_southeast   -316.768821       316.768821\n8  region_southwest   -262.565457       262.565457\n0               age    259.279913       259.279913\n6  region_northwest    220.532938       220.532938\n1               sex   -137.297299       137.297299\n\n\n\n\nCode\n# Graficamos los coeficientes ordenados de mayor a menor en un gráfico de barras\nsns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\nplt.xlabel('Coeficiente')\nplt.ylabel('Variable')\nplt.title('Coeficientes de la regresión lineal')\nplt.show()\n\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18208\\3043957422.py:2: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n\n\nCalculamos las métricas de evaluación del modelo (haciendo predicciones sobre el conjunto de prueba)\nEn el contexto de la regresión lineal, es fundamental evaluar el rendimiento del modelo para entender su precisión y capacidad de generalización. Existen varias métricas de evaluación que nos ayudan a cuantificar el error y la calidad de las predicciones del modelo. Entre las más comunes se encuentran:\n\nMean Squared Error (MSE): Esta métrica calcula el promedio de los cuadrados de los errores, es decir, la diferencia entre los valores predichos \\(\\hat{y}_i\\) y los valores reales \\(y_i\\). El MSE penaliza fuertemente los errores grandes debido a la elevación al cuadrado, lo que lo convierte en una métrica sensible a los outliers. Un MSE más bajo indica un mejor ajuste del modelo a los datos. La fórmula del MSE es:\n\\(\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\ndonde \\(n\\) es el número de observaciones.\nR-squared (R²): También conocido como coeficiente de determinación, esta métrica indica la proporción de la varianza en la variable dependiente que es explicada por las variables independientes del modelo. El valor de \\(R^2\\) varía entre \\(0\\) y \\(1\\), donde un valor más cercano a \\(1\\) indica que el modelo explica bien la variabilidad de los datos. Un \\(R^2\\) de \\(0\\) significa que el modelo no explica ninguna variabilidad, mientras que un \\(R^2\\) de \\(1\\) significa que el modelo explica toda la variabilidad. La fórmula del \\(R^2\\) es:\n\\(R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\)\ndonde \\(\\bar{y}\\) es el valor medio de los valores reales \\(y_i\\).\nMean Absolute Error (MAE): Esta métrica calcula el promedio de los errores absolutos, es decir, la diferencia absoluta entre los valores predichos \\(\\hat{y}_i\\) y los valores reales \\(y_i\\). A diferencia del MSE, el MAE no penaliza tanto los errores grandes, lo que lo hace más robusto frente a outliers. Un MAE más bajo indica un mejor rendimiento del modelo. La fórmula del MAE es:\n\\(\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\)\ndonde \\(n\\) es el número de observaciones.\n\nEstas métricas proporcionan diferentes perspectivas sobre el rendimiento del modelo y, al utilizarlas en conjunto, se puede obtener una evaluación más completa y robusta de la calidad de las predicciones del modelo de regresión lineal.\n\n\nCode\n# Realizamos predicciones sobre el conjunto de prueba\ny_pred = modelo_regresion.predict(X_test)\n\n# Importamos las métricas para evaluar el modelo\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# Calculamos las métricas de evaluación\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\n\n# Imprimimos las métricas de evaluación\nprint(f'Error Cuadrático Medio (MSE): {mse}')\nprint(f'Coeficiente de Determinación (R^2): {r2}')\nprint(f'Error Absoluto Medio (MAE): {mae}')\n\n\nError Cuadrático Medio (MSE): 36077869.003987625\nCoeficiente de Determinación (R^2): 0.7224601674430706\nError Absoluto Medio (MAE): 3961.341098850965\n\n\n\n\nRealizamos predicciones para un nuevo usuario de la aseguradora\n\n\nCode\n# Definimos un nuevo caso de prueba con los siguientes valores\nnuevo_caso = pd.DataFrame({\n    'age': [30],  # Edad\n    'sex': [1],  # Género (0: mujer, 1: hombre)\n    'bmi': [19],  # Índice de masa corporal\n    'children': [1],  # Número de hijos\n    'smoker': [0],  # Fumador (0: no, 1: sí)\n    'region_northeast': [0],  # Región noreste\n    'region_northwest': [1],  # Región noroeste\n    'region_southeast': [0],  # Región sureste\n    'region_southwest': [0]  # Región suroeste\n})\n\n# Realizamos la predicción con el nuevo caso de prueba\nprediccion = modelo_regresion.predict(nuevo_caso)\n\n# Imprimimos el resultado de la predicción\nprint(f'El costo estimado del seguro médico es: ${prediccion[0]:.2f}')\n\n\nEl costo estimado del seguro médico es: $2145.37\n\n\nEn el caso de una regresión múltiple, donde tienes más de una variable independiente, la relación entre las variables independientes y la variable dependiente se representa en un espacio de dimensiones superiores. Por lo tanto, en lugar de una línea de regresión (que es aplicable en regresión simple con una sola variable independiente), tendrías un hiperplano en un espacio multidimensional.\nSin embargo, puedes visualizar la relación entre los valores reales y los valores predichos en un gráfico de dispersión, como se muestra a continuación. Este tipo de gráfico es útil para evaluar la precisión de las predicciones del modelo.\n\n\nCode\n# Graficamos los valores reales vs los valores predichos\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, y_pred, color='blue', alpha=0.7, s=10)\nplt.title('Cargos reales vs. Cargos predichos')\nplt.xlabel('Valores reales')\nplt.ylabel('Valores predichos')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Línea de referencia\nplt.legend(['Valores predichos', 'Línea de referencia'])\nplt.show()\n\n\n\n\n\n\n\n\n\nEn este gráfico: - Los puntos azules representan los valores reales frente a los valores predichos. - La línea roja discontinua es una línea de referencia que indica dónde estarían los puntos si las predicciones fueran perfectas (es decir, \\(y_{\\text{real}} = y_{\\text{predicho}}\\)).\nEste gráfico te permite visualizar cómo de cerca están las predicciones de los valores reales. Si las predicciones son perfectas, todos los puntos caerán sobre la línea de referencia.\nNota: Los valores predichos negativos en un modelo de regresión lineal pueden ocurrir debido a la naturaleza de la ecuación de regresión, que no impone restricciones sobre el rango de los valores predichos. En el contexto de los cargos médicos, los valores negativos no tienen sentido práctico, ya que los costos médicos no pueden ser negativos.\nPara abordar este problema, puedes considerar las siguientes opciones:\n\nTransformación de los datos: Asegúrate de que las características y la variable objetivo estén adecuadamente transformadas y escaladas. A veces, una transformación logarítmica puede ayudar a manejar mejor los datos.\nModelos con restricciones: Utiliza modelos que impongan restricciones en los valores predichos, como la regresión lineal con restricciones (por ejemplo, LinearRegression con positive=True en scikit-learn).\nPost-procesamiento de las predicciones: Después de realizar las predicciones, puedes ajustar los valores negativos a cero, ya que los costos médicos no pueden ser negativos."
  },
  {
    "objectID": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#regresión-lineal-simple",
    "href": "Supervised Learning - Regresion lineal para predecir cargos medicos.html#regresión-lineal-simple",
    "title": "Aprendizaje Supervisado",
    "section": "Regresión Lineal Simple",
    "text": "Regresión Lineal Simple\nComo ejemplo, se puede ajustar una característica con una regresión lineal simple. Esto permitirá visualizar la relación entre una sola variable independiente y la variable dependiente.\nVamos a ajustar una regresión lineal simple utilizando una característica, por ejemplo, bmi.\n\n\nCode\n# Copio la base de datos 'insurance.csv' en un nuevo DataFrame\ndf = insurance.copy()\n\nX_2 = df[['bmi']]\ny_2 = df['charges']\n\n# Dividir los datos en conjuntos de entrenamiento y prueba\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)\n\n# Crear y entrenar el modelo de regresión lineal\nmodel = LinearRegression()\nmodel.fit(X_train2, y_train2)\n\n# Realizar predicciones\ny_pred = model.predict(X_test2)\n\n# Graficar los datos y la línea de regresión\nplt.figure(figsize=(5, 3))\nplt.scatter(X_test2, y_test2, color='blue', alpha=0.7, s=10, label='Datos reales')\nplt.plot(X_test2, y_pred, color='red', linewidth=0.5, label='Línea de regresión')\nplt.title('Regresión lineal simple: BMI vs. Cargos médicos')\nplt.xlabel('BMI')\nplt.ylabel('Cargos médicos')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Extraer los coeficientes de la regresión lineal\ncoeficientes = model.coef_\nintercepto = model.intercept_\n\n# Imprimir la ecuaicón de la recta de regresión\nprint(f'Ecuación de la recta de regresión: y = {coeficientes[0]:.2f}X + {intercepto:.2f}')\n\n\nEcuación de la recta de regresión: y = 392.44X + 1353.07\n\n\nEn este ejemplo:\n\nDatos: Utilizamos la característica bmi y la variable objetivo charges.\nDivisión de datos: Dividimos los datos en conjuntos de entrenamiento y prueba.\nModelo: Creamos y entrenamos un modelo de regresión lineal simple.\nPredicciones: Realizamos predicciones sobre el conjunto de prueba.\nGráfico: Graficamos los datos reales y la línea de regresión ajustada.\n\nEste gráfico te permitirá visualizar cómo la edad se relaciona con los cargos médicos y cómo la línea de regresión ajustada representa esta relación.\n\nTrabajo individual\nStep 1. Buscar una nueva base de datos: - Buscar una base de datos nueva e identificar la(s) variable(s) predictora(s) y objetivo.\n\n\nCode\n# Instalamos los paquetes necesarios\n#%pip install scikit-learn # Paquete de machine learning con algoritmos de clasificación, regresión, clustering, etc.\n#%pip install pandas\n#%pip install matplotlib\n#%pip install seaborn\n\n# Importamos los paquetes necesarios\nfrom sklearn.linear_model import LinearRegression # Regresión lineal con scikit-learn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n\nStep 2. Cargamos y limpiamos la base de datos\n\n\nCode\n# Cargamos la base de datos 'Dh.csv'\nDh = pd.read_csv('D:/Maestria_AI/Actividad6/ant_20222016_Dh_adjslp_pts.csv')\n\n# Revisamos los tipos de datos por cada columna con el método 'info()' del DataFrame 'transacciones'\nDh.info()\n# Revisamos los valores nulos en el DataFrame 'transacciones' con el método 'isnull().sum()'\nDh.isnull().sum()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 12749 entries, 0 to 12748\nData columns (total 9 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   VALUE   12749 non-null  float64\n 1   Este    12749 non-null  float64\n 2   Norte   12749 non-null  float64\n 3   asp1    12745 non-null  float64\n 4   rgh1    12745 non-null  float64\n 5   slp1    12745 non-null  float64\n 6   tpi1    12745 non-null  float64\n 7   tri1    12742 non-null  float64\n 8   elev1   12749 non-null  float64\ndtypes: float64(9)\nmemory usage: 896.5 KB\n\n\nVALUE    0\nEste     0\nNorte    0\nasp1     4\nrgh1     4\nslp1     4\ntpi1     4\ntri1     7\nelev1    0\ndtype: int64\n\n\n\n\nCode\n# Eliminamos valores nulos en el DataFrame 'transacciones' con el método 'dropna()'\nDh_cln = Dh.dropna()\n# Revisamos los tipos de datos por cada columna con el método 'info()' del DataFrame 'transacciones'\nDh_cln.info()\n# Revisamos los valores nulos en el DataFrame 'transacciones' con el método 'isnull().sum()'\nDh_cln.isnull().sum()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 12742 entries, 0 to 12748\nData columns (total 9 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   VALUE   12742 non-null  float64\n 1   Este    12742 non-null  float64\n 2   Norte   12742 non-null  float64\n 3   asp1    12742 non-null  float64\n 4   rgh1    12742 non-null  float64\n 5   slp1    12742 non-null  float64\n 6   tpi1    12742 non-null  float64\n 7   tri1    12742 non-null  float64\n 8   elev1   12742 non-null  float64\ndtypes: float64(9)\nmemory usage: 995.5 KB\n\n\nVALUE    0\nEste     0\nNorte    0\nasp1     0\nrgh1     0\nslp1     0\ntpi1     0\ntri1     0\nelev1    0\ndtype: int64\n\n\n\n\nCode\n# Visualizamos las primeras 5 filas de la base de datos cargada\nDh_cln.head(5)\n\n\n\n\n\n\n\n\n\nVALUE\nEste\nNorte\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\n\n\n\n\n0\n5.083925\n816872.728\n9947471.064\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n\n\n1\n4.190065\n816876.728\n9947471.064\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n\n\n2\n3.812052\n816880.728\n9947471.064\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n\n\n3\n3.402457\n816884.728\n9947471.064\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n\n\n4\n3.139728\n816888.728\n9947471.064\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n\n\n\n\n\n\n\nStep 3. Aislamos y preparamos las variables X y y\n\n\nCode\n# Seleccionamos las variable independiente (X)\nX = Dh_cln.drop(['VALUE', 'Este', 'Norte'], axis=1)\nX.head(5)\n\n\n\n\n\n\n\n\n\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\n\n\n\n\n0\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n\n\n1\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n\n\n2\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n\n\n3\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n\n\n4\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n\n\n\n\n\n\n\n\n\nCode\n# Seleccionamos la variable dependiente (y)\ny = Dh_cln['VALUE']\ny.head(5)\n\n\n0    5.083925\n1    4.190065\n2    3.812052\n3    3.402457\n4    3.139728\nName: VALUE, dtype: float64\n\n\nStep 4. Verificamos la multilinearidad entre las variables predictoras\n\n\nCode\n# Calcular matriz de correlación\ncorrelation_matrix = X.corr()\nprint(correlation_matrix)\n\n# Visualizar matriz de correlación\nplt.figure(figsize=(7, 5))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Matriz de Correlación de los predictores')\nplt.show()\n\n\n           asp1      rgh1      slp1      tpi1      tri1     elev1\nasp1   1.000000 -0.090123 -0.123981 -0.016804 -0.196174 -0.052206\nrgh1  -0.090123  1.000000  0.918919 -0.033872  0.628598  0.328279\nslp1  -0.123981  0.918919  1.000000 -0.021939  0.458742  0.328997\ntpi1  -0.016804 -0.033872 -0.021939  1.000000 -0.050873 -0.009272\ntri1  -0.196174  0.628598  0.458742 -0.050873  1.000000  0.230653\nelev1 -0.052206  0.328279  0.328997 -0.009272  0.230653  1.000000\n\n\n\n\n\n\n\n\n\nStep 5. Ajustamos el modelo como baseline - Ajusta un modelo de regresión lineal. - Evalúa el rendimiento del modelo (ejm: MSE).\n\n\nCode\n# Dividimos los datos en conjuntos de entrenamiento y prueba\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n\n\nCode\n# Instanciamos un modelo de Regresión Lineal y lo ajustamos con los valores de `X_train` y `y_train`\n# Creamos una instancia del modelo de regresión lineal\nmodelo_regresion = LinearRegression()\n\n# Ajustamos el modelo a los datos de entrenamiento\nmodelo_regresion.fit(X_train, y_train)\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\n\n\nCode\n# Obtenemos los coeficientes del modelo\ncoeficientes = modelo_regresion.coef_\n# Obtenemos el intercepto \nintercepto = modelo_regresion.intercept_\n\n# Imprimimos coeficientes e intercepto\nprint(coeficientes, intercepto)\n\n# Definimos la ecuación de la recta de regresión\necuacion_recta = 'y = ' + ' + '.join([f'{coeficientes[i]}*X{i}' for i in range(len(coeficientes))]) + f' + {intercepto}'\nprint(f'Ecuación de la recta de regresión: {ecuacion_recta}')\n\n\n[-6.00389976e-03 -9.50081199e-03 -8.92668120e-02  1.45844363e+00\n  1.83096174e-01  6.42400935e-04] 2.2544957230039744\nEcuación de la recta de regresión: y = -0.006003899763952534*X0 + -0.009500811991926553*X1 + -0.08926681198535044*X2 + 1.458443630580392*X3 + 0.18309617442556023*X4 + 0.0006424009345539251*X5 + 2.2544957230039744\n\n\n\n\nCode\n# Crear un DataFrame para facilitar la interpretación\ncoef_df = pd.DataFrame({'Variable': X.columns, 'Coeficiente': coeficientes})\n\n# Ordenar por el valor absoluto del coeficiente para ver cuáles son más importantes\ncoef_df['Abs_Coeficiente'] = coef_df['Coeficiente'].abs()\n\n# Ordenamos los coeficientes de mayor a menor\ncoef_df = coef_df.sort_values(by='Abs_Coeficiente', ascending=False)\n\nprint(coef_df)\n\n# Graficamos los coeficientes ordenados de mayor a menor en un gráfico de barras\nsns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\nplt.xlabel('Coeficiente')\nplt.ylabel('Variable')\nplt.title('Coeficientes de la regresión lineal')\nplt.show()\n\n\n  Variable  Coeficiente  Abs_Coeficiente\n3     tpi1     1.458444         1.458444\n4     tri1     0.183096         0.183096\n2     slp1    -0.089267         0.089267\n1     rgh1    -0.009501         0.009501\n0     asp1    -0.006004         0.006004\n5    elev1     0.000642         0.000642\n\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20020\\1682869153.py:13: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\nStep 6. Contribucion relativa de las variables predictoras mediante modelo SHARP - (Opcional) Usa la librería SHAP para explicar de manera gráfica la salida del modelo (por ejemplo, puedes crear un objeto explainer con el modelo y los datos de entrenamiento, y calcular los valores SHAP).\n\n\nCode\n# Instala SHAP\n%pip install shap\n\n# Importa SHAP\nimport shap \n\n# Crea un objeto explainer con el modelo y los datos de entrenamiento\nexplainer = shap.Explainer(modelo_regresion, X_train)\n\n# Calcula los valores SHAP para todos los datos de prueba\nshap_values = explainer(X_test)\n\n# Grafica los valores SHAP\nshap.summary_plot(shap_values, X_test, plot_type='bar')\n\n## Grafica los valores SHAP para un punto de datos específico\n## Inicializa los gráficos interactivos\nshap.initjs()\n\n# Grafica la contribución de cada variable para la primera fila\nshap.force_plot(\n    explainer.expected_value,\n    shap_values.values[0],   # usar .values para convertir SHAP object a array\n    X_test.iloc[0]\n)\n\n\nRequirement already satisfied: shap in d:\\maestria_ai\\.venv\\lib\\site-packages (0.48.0)\nRequirement already satisfied: numpy in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (2.1.3)\nRequirement already satisfied: scipy in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (1.15.3)\nRequirement already satisfied: scikit-learn in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (1.7.1)\nRequirement already satisfied: pandas in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (2.3.2)\nRequirement already satisfied: tqdm&gt;=4.27.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (4.67.1)\nRequirement already satisfied: packaging&gt;20.9 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (25.0)\nRequirement already satisfied: slicer==0.0.8 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (0.0.8)\nRequirement already satisfied: numba&gt;=0.54 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (0.61.0)\nRequirement already satisfied: cloudpickle in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (3.1.1)\nRequirement already satisfied: typing-extensions in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (4.15.0)\nRequirement already satisfied: llvmlite&lt;0.45,&gt;=0.44.0dev0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from numba&gt;=0.54-&gt;shap) (0.44.0)\nRequirement already satisfied: colorama in d:\\maestria_ai\\.venv\\lib\\site-packages (from tqdm&gt;=4.27.0-&gt;shap) (0.4.6)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\maestria_ai\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;shap) (1.17.0)\nRequirement already satisfied: joblib&gt;=1.2.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from scikit-learn-&gt;shap) (1.5.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from scikit-learn-&gt;shap) (3.6.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Visualization omitted, Javascript library not loaded!\n  Have you run `initjs()` in this notebook? If this notebook was from another\n  user you must also trust this notebook (File -&gt; Trust notebook). If you are viewing\n  this notebook on github the Javascript has been stripped for security. If you are using\n  JupyterLab this error is because a JupyterLab extension has not yet been written.\n\n \n\n\n\n\nCode\n# Eliminamos la variable que menos aporta y que tiene un alata depedencia entre si\nX = X.drop(['rgh1'], axis=1)\nX.head(5)\n\n\n\n\n\n\n\n\n\nasp1\nslp1\ntpi1\ntri1\nelev1\n\n\n\n\n0\n0.109970\n20.886478\n-0.075195\n1.031517\n4861.926758\n\n\n1\n350.337708\n20.204298\n-0.185059\n0.905296\n4861.905273\n\n\n2\n343.757568\n19.912228\n-0.005859\n0.305124\n4862.399414\n\n\n3\n335.548126\n20.086668\n-0.081055\n0.596693\n4862.826172\n\n\n4\n346.701843\n16.271687\n0.032715\n0.829091\n4863.404297\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\n\n# Dividimos los datos en conjuntos de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. Escalar SOLO con entrenamiento\nscaler = StandardScaler()\n# El escalador aprende de las caracteristicas de X_train.\n# El X_test se transforma con los mismos factores de X_train manteniendo las caracteristicas\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n\n\nCode\n# Creamos una instancia del modelo de regresión lineal\nmodelo_regresion = LinearRegression()\n\n# Ajustamos el modelo a los datos de entrenamiento\nmodelo_regresion.fit(X_train_scaled, y_train)\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\n\n\nCode\n# Obtenemos los coeficientes del modelo\ncoeficientes = modelo_regresion.coef_\n# Obtenemos el intercepto \nintercepto = modelo_regresion.intercept_\n\n# Imprimimos coeficientes e intercepto\nprint(coeficientes, intercepto)\n\n# Definimos la ecuación de la recta de regresión\necuacion_recta = 'y = ' + ' + '.join([f'{coeficientes[i]}*X{i}' for i in range(len(coeficientes))]) + f' + {intercepto}'\nprint(f'Ecuación de la recta de regresión: {ecuacion_recta}')\n\n\n[-0.29160042 -0.78310596  0.33281607  0.27832457  0.12081876] 1.1804317057284412\nEcuación de la recta de regresión: y = -0.29160042318617885*X0 + -0.7831059645303692*X1 + 0.33281606518082807*X2 + 0.2783245689560943*X3 + 0.12081875911772214*X4 + 1.1804317057284412\n\n\n\n\nCode\n# Crear un DataFrame para facilitar la interpretación\ncoef_df = pd.DataFrame({'Variable': X.columns, 'Coeficiente': coeficientes})\n\n# Ordenar por el valor absoluto del coeficiente para ver cuáles son más importantes\ncoef_df['Abs_Coeficiente'] = coef_df['Coeficiente'].abs()\n\n# Ordenamos los coeficientes de mayor a menor\ncoef_df = coef_df.sort_values(by='Abs_Coeficiente', ascending=False)\n\nprint(coef_df)\n\n# Graficamos los coeficientes ordenados de mayor a menor en un gráfico de barras\nsns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\nplt.xlabel('Coeficiente')\nplt.ylabel('Variable')\nplt.title('Coeficientes de la regresión lineal')\nplt.show()\n\n\n  Variable  Coeficiente  Abs_Coeficiente\n1     slp1    -0.783106         0.783106\n2     tpi1     0.332816         0.332816\n0     asp1    -0.291600         0.291600\n3     tri1     0.278325         0.278325\n4    elev1     0.120819         0.120819\n\n\nC:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20020\\1682869153.py:13: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette='coolwarm')\n\n\n\n\n\n\n\n\n\n\n\nContribucion relativa de las variables predictoras mediante modelo SHARP:\n\n(Opcional) Usa la librería SHAP para explicar de manera gráfica la salida del modelo (por ejemplo, puedes crear un objeto explainer con el modelo y los datos de entrenamiento, y calcular los valores SHAP).\n\n\n\nCode\n# Instala SHAP\n%pip install shap\n\n# Importa SHAP\nimport shap \n\n# Crea un objeto explainer con el modelo y los datos de entrenamiento\nexplainer = shap.Explainer(modelo_regresion, X_train)\n\n# Calcula los valores SHAP para todos los datos de prueba\nshap_values = explainer(X_test_scaled)\n\n# Grafica los valores SHAP\nshap.summary_plot(shap_values, X_test_scaled, plot_type='bar')\n\n## Grafica los valores SHAP para un punto de datos específico\n## Inicializa los gráficos interactivos\nshap.initjs()\n\n# Grafica la contribución de cada variable para la primera fila\nshap.force_plot(\n    explainer.expected_value,\n    shap_values.values[0],   # usar .values para convertir SHAP object a array\n    X_test.iloc[0]\n)\n\n\nRequirement already satisfied: shap in d:\\maestria_ai\\.venv\\lib\\site-packages (0.48.0)\nRequirement already satisfied: numpy in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (2.1.3)\nRequirement already satisfied: scipy in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (1.15.3)\nRequirement already satisfied: scikit-learn in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (1.7.1)\nRequirement already satisfied: pandas in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (2.3.2)\nRequirement already satisfied: tqdm&gt;=4.27.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (4.67.1)\nRequirement already satisfied: packaging&gt;20.9 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (25.0)\nRequirement already satisfied: slicer==0.0.8 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (0.0.8)\nRequirement already satisfied: numba&gt;=0.54 in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (0.61.0)\nRequirement already satisfied: cloudpickle in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (3.1.1)\nRequirement already satisfied: typing-extensions in d:\\maestria_ai\\.venv\\lib\\site-packages (from shap) (4.15.0)\nRequirement already satisfied: llvmlite&lt;0.45,&gt;=0.44.0dev0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from numba&gt;=0.54-&gt;shap) (0.44.0)\nRequirement already satisfied: colorama in d:\\maestria_ai\\.venv\\lib\\site-packages (from tqdm&gt;=4.27.0-&gt;shap) (0.4.6)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in d:\\maestria_ai\\.venv\\lib\\site-packages (from pandas-&gt;shap) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in d:\\maestria_ai\\.venv\\lib\\site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;shap) (1.17.0)\nRequirement already satisfied: joblib&gt;=1.2.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from scikit-learn-&gt;shap) (1.5.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in d:\\maestria_ai\\.venv\\lib\\site-packages (from scikit-learn-&gt;shap) (3.6.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  Visualization omitted, Javascript library not loaded!\n  Have you run `initjs()` in this notebook? If this notebook was from another\n  user you must also trust this notebook (File -&gt; Trust notebook). If you are viewing\n  this notebook on github the Javascript has been stripped for security. If you are using\n  JupyterLab this error is because a JupyterLab extension has not yet been written.\n\n \n\n\n\n\nCode\n# Realizamos predicciones sobre el conjunto de prueba\ny_pred = modelo_regresion.predict(X_test_scaled)\n\n# Importamos las métricas para evaluar el modelo\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, root_mean_squared_error\n\n# Calculamos las métricas de evaluación\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred) # # Varianza explicada (R^2) en los datos de entrenamiento\nmae = mean_absolute_error(y_test, y_pred)\nrmse = root_mean_squared_error(y_test, y_pred)\n\n# Imprimimos las métricas de evaluación\nprint(f'Error Cuadrático Medio (MSE): {mse}')\nprint(f'Coeficiente de Determinación (R^2): {r2}')\nprint(f'Error Absoluto Medio (MAE): {mae}')\nprint(f'Raíz del error cuadrático medio (RMSE): {rmse}')\n\n\nError Cuadrático Medio (MSE): 8.674495586828417\nCoeficiente de Determinación (R^2): 0.07373069241293118\nError Absoluto Medio (MAE): 2.0717954261916236\nRaíz del error cuadrático medio (RMSE): 2.9452496646003405\n\n\n\nPredicción de Nuevos Registros:\n\nUtiliza el modelo ajustado para predecir el valor de y de un nuevo registro.\n\n\n\n\nCode\nX_train_scaled\n\n\narray([[-1.04731262e+00, -1.00475265e-01, -1.54309210e-01,\n        -4.62720297e-01,  1.02826044e+00],\n       [ 2.40183919e-01, -9.57886144e-01, -1.35051654e-01,\n        -4.98319966e-01, -1.11533969e+00],\n       [-5.93035181e-01, -8.90326678e-01, -4.09035987e-02,\n        -3.36323292e-01, -1.02848039e+00],\n       ...,\n       [ 6.95141879e-01, -6.35739195e-01,  1.05891686e+00,\n         4.30450406e-01, -5.26364307e-01],\n       [ 1.10684225e+00,  7.43086477e-01,  2.13724095e-01,\n        -4.41925736e-01, -1.21415005e+00],\n       [ 2.12995992e-01, -1.29546398e-01, -3.38325863e-01,\n        -2.39427084e-04, -1.58143771e-01]])\n\n\n\n\nCode\n# Definimos un nuevo caso de prueba con los siguientes valores\nnuevo_caso = pd.DataFrame({\n    'asp1': [-1.25],  # Orientacion\n    'slp1': [0.48],  # Pendiente\n    'tpi1': [-0.25],  # Índice de posición topográfica\n    'tri1': [0.45],  # Índice de Rugosidad del Terreno\n    'elev1': [1.02],  # Región noreste\n})\n\n# Realizamos la predicción con el nuevo caso de prueba\nprediccion = modelo_regresion.predict(nuevo_caso)\n\n# Imprimimos el resultado de la predicción\nprint(f'El valor de Dh estimado es: {prediccion[0]:.2f} m')\n\n\nEl valor de Dh estimado es: 1.33 m\n\n\nd:\\Maestria_AI\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n  warnings.warn(\n\n\n\n\nCode\n# Graficamos los valores reales vs los valores predichos\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, y_pred, color='blue', alpha=0.7, s=10)\nplt.title('Dh reales vs. Dh predichos')\nplt.xlabel('Valores reales')\nplt.ylabel('Valores predichos')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Línea de referencia\nplt.legend(['Valores predichos', 'Línea de referencia'])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAnálisis del mejor ajuste:\n\n(Opcional) Usa cross_val_score con 5 folds. Calcula la media del MSE y la desviación estándar de todos los scores obtenidos con la validación cruzada (opcional)."
  },
  {
    "objectID": "Ejercicio/point_samples.html",
    "href": "Ejercicio/point_samples.html",
    "title": "Machine Learning",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  },
  {
    "objectID": "Ejercicio/ant_20222016_Dh_adjslp_pts.html",
    "href": "Ejercicio/ant_20222016_Dh_adjslp_pts.html",
    "title": "Machine Learning",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n         0 0     false"
  },
  {
    "objectID": "midterm.html",
    "href": "midterm.html",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "",
    "text": "Es un método estadístico que se enfoca en analizar la relación lineal entre dos variables:\n\nUna variable independiente X (por ejemplo: horas de estudio)\nUna variable dependiente Y\n\nEl modelo tiene esta forma:\nY = b0 + b1*X\nDonde:\n\nb0: es la intersección (intercepto). Es el valor de Y cuando X = 0.\n\nb1: es la pendiente de la recta, y representa cuánto cambia Y por cada unidad que aumenta X.\n\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos, es decir que exista una minima diferencia entre el valor real y lo predicho. Este es el criterio de mínimos cuadrados."
  },
  {
    "objectID": "midterm.html#importando-librerias",
    "href": "midterm.html#importando-librerias",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "0. Importando librerias",
    "text": "0. Importando librerias\nSe importan las librerias desde los paquetes\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport seaborn as sns"
  },
  {
    "objectID": "midterm.html#carga-y-exploración-inicial-del-dataset.",
    "href": "midterm.html#carga-y-exploración-inicial-del-dataset.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "1. Carga y exploración inicial del dataset.",
    "text": "1. Carga y exploración inicial del dataset.\nSe cargan los datos del archivo .csv, que proviene de una cobertura de puntos en formato shapefile.La tabla contiene atributos asociados a los balanves de masa.\n\n\nCode\ndf = gpd.read_file(\"ant_20222016_Dh_adjslp_pts.dbf\")\n# Ver primeras filas\ndf.head()\n\n\n\n\n\n\n\n\n\nVALUE\nEste\nNorte\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\nprec1\ntmed1\ndhdt\ngeometry\n\n\n\n\n0\n5.083925\n816872.728\n9947471.064\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n1597.466675\n4\n0.847321\nNone\n\n\n1\n4.190065\n816876.728\n9947471.064\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n1597.466675\n4\n0.698344\nNone\n\n\n2\n3.812052\n816880.728\n9947471.064\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n1597.466675\n4\n0.635342\nNone\n\n\n3\n3.402457\n816884.728\n9947471.064\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n1597.466675\n4\n0.567076\nNone\n\n\n4\n3.139728\n816888.728\n9947471.064\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n1597.466675\n4\n0.523288\nNone\n\n\n\n\n\n\n\nSe identifican las variables con valores faltantes y se visualizan en un gráfico de barras. sto permite decidir si imputar valores o eliminar registros incompletos.\n\n\nCode\n# Porcentaje de valores faltantes por columna\nnan_percent = df.isna().mean() * 100\nnan_percent_sorted = nan_percent.sort_values(ascending=False).round(2)\n\nprint(\"Porcentaje de valores faltantes por columna:\")\nprint(nan_percent_sorted)\n\n# === Visualización opcional con gráfico de barras ===\nnan_percent_sorted[nan_percent_sorted &gt; 0].plot(\n    kind='barh', color='salmon', figsize=(8,5)\n)\nplt.title(\"Porcentaje de valores faltantes por variable\")\nplt.xlabel(\"Porcentaje (%)\")\nplt.ylabel(\"Variable\")\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.show()\n\n\nPorcentaje de valores faltantes por columna:\ngeometry    100.00\ntri1          0.05\nasp1          0.03\nrgh1          0.03\nslp1          0.03\ntpi1          0.03\nVALUE         0.00\nEste          0.00\nNorte         0.00\nelev1         0.00\nprec1         0.00\ntmed1         0.00\ndhdt          0.00\ndtype: float64\n\n\n\n\n\n\n\n\n\nLa seleccion de seleccion de variables considera: VALUE: variable dependiente (0 = sin deslizamiento, 1 = con deslizamiento) features: variables explicativas derivadas del terreno o clima Se eliminan filas con valores faltantes.\n\n\nCode\n# La tercera columna ('desliz_occ') es la variable dependiente (0 = no, 1 = sí)\ntarget_col = 'dhdt'\n\n# Seleccion de variables explicativas numéricas\n# Excluimos 'slp1','tri1', 'elev1'\n# Puedes ajustar según tus columnas reales\nfeatures = [\n    'asp1', 'rgh1',  \n    'tpi1', 'prec1', #'tmed1',\n]\n\n# Eliminacion filas con NaN\ndf_clean = df.dropna(subset=features + [target_col])\ndf_clean\n\n\n\n\n\n\n\n\n\nVALUE\nEste\nNorte\nasp1\nrgh1\nslp1\ntpi1\ntri1\nelev1\nprec1\ntmed1\ndhdt\ngeometry\n\n\n\n\n0\n5.083925\n816872.728\n9947471.064\n0.109970\n1.692383\n20.886478\n-0.075195\n1.031517\n4861.926758\n1597.466675\n4\n0.847321\nNone\n\n\n1\n4.190065\n816876.728\n9947471.064\n350.337708\n1.587891\n20.204298\n-0.185059\n0.905296\n4861.905273\n1597.466675\n4\n0.698344\nNone\n\n\n2\n3.812052\n816880.728\n9947471.064\n343.757568\n1.791992\n19.912228\n-0.005859\n0.305124\n4862.399414\n1597.466675\n4\n0.635342\nNone\n\n\n3\n3.402457\n816884.728\n9947471.064\n335.548126\n1.941406\n20.086668\n-0.081055\n0.596693\n4862.826172\n1597.466675\n4\n0.567076\nNone\n\n\n4\n3.139728\n816888.728\n9947471.064\n346.701843\n1.399414\n16.271687\n0.032715\n0.829091\n4863.404297\n1597.466675\n4\n0.523288\nNone\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n12744\n3.653540\n818000.728\n9946483.064\n286.290894\n1.176758\n12.845374\n-0.012207\n0.600953\n5676.818359\n1620.902954\n1\n0.608923\nNone\n\n\n12745\n2.058196\n818004.728\n9946483.064\n313.943970\n0.792969\n8.523555\n0.015137\n0.545106\n5677.481445\n1620.902954\n1\n0.343033\nNone\n\n\n12746\n3.595429\n817996.728\n9946479.064\n325.155609\n1.776367\n18.057718\n-0.006348\n0.829797\n5676.610352\n1620.902954\n1\n0.599238\nNone\n\n\n12747\n3.493276\n818000.728\n9946479.064\n312.475830\n1.260742\n12.594838\n0.014160\n0.402667\n5677.309570\n1620.902954\n1\n0.582213\nNone\n\n\n12748\n2.510170\n818004.728\n9946479.064\n308.570496\n1.098633\n10.395593\n0.020508\n0.225643\n5677.936523\n1620.902954\n1\n0.418362\nNone\n\n\n\n\n12745 rows × 13 columns\n\n\n\n\n\nCode\n# Crear subconjunto de datos\nX = df_clean[features]\ny = df_clean[target_col].astype(float)\n# Verificar valores faltantes\nX.info()\nX.describe()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 12745 entries, 0 to 12748\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   asp1    12745 non-null  float64\n 1   rgh1    12745 non-null  float64\n 2   tpi1    12745 non-null  float64\n 3   prec1   12745 non-null  float64\ndtypes: float64(4)\nmemory usage: 497.9 KB\n\n\n\n\n\n\n\n\n\nasp1\nrgh1\ntpi1\nprec1\n\n\n\n\ncount\n12745.000000\n12745.000000\n12745.000000\n12745.000000\n\n\nmean\n302.222725\n3.209007\n-0.002589\n1607.246096\n\n\nstd\n48.370283\n1.380399\n0.230966\n5.351926\n\n\nmin\n0.007507\n0.428711\n-7.901855\n1597.466675\n\n\n25%\n291.430939\n2.405273\n-0.048340\n1602.755249\n\n\n50%\n311.032043\n2.984375\n0.001465\n1606.763550\n\n\n75%\n326.036591\n3.654297\n0.047852\n1610.514771\n\n\nmax\n359.985260\n26.353516\n8.570801\n1620.902954\n\n\n\n\n\n\n\nLa matriz de correlacion permite identificar colinealidad entre variables explicativas. Valores altos (&gt;0.8 o &lt;−0.8) pueden indicar redundancia entre variables.\n\n\nCode\n# --- Asegurar que solo se usen variables numéricas ---\ncorrelation_matrix = X.corr()\nprint(correlation_matrix)\n\n# Visualizar matriz de correlación\nplt.figure(figsize=(7, 5))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Matriz de Correlación de los predictores')\nplt.show()\n\n\n           asp1      rgh1      tpi1     prec1\nasp1   1.000000 -0.089663 -0.015036 -0.047092\nrgh1  -0.089663  1.000000 -0.074002  0.333880\ntpi1  -0.015036 -0.074002  1.000000 -0.017936\nprec1 -0.047092  0.333880 -0.017936  1.000000"
  },
  {
    "objectID": "midterm.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "href": "midterm.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "2. División en conjuntos de entrenamiento y prueba (train_test_split).",
    "text": "2. División en conjuntos de entrenamiento y prueba (train_test_split).\nSe dividen los datos: - 80% para entrenar el modelo - 20% para evaluar su desempeño\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(\"Tamaño entrenamiento:\", X_train.shape)\nprint(\"Tamaño prueba:\", X_test.shape)\n\n\nTamaño entrenamiento: (10196, 4)\nTamaño prueba: (2549, 4)"
  },
  {
    "objectID": "midterm.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "href": "midterm.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "3. Definición y entrenamiento del modelo utilizando Pipeline.",
    "text": "3. Definición y entrenamiento del modelo utilizando Pipeline.\nEtapas del pipeline:\n\nImputer: reemplaza valores faltantes por la media.\nScaler: estandariza las variables (media = 0, desviación = 1).\nRegresión logística: modelo lineal que estima la probabilidad de deslizamiento.\nclass_weight=‘balanced’: ajusta el peso de las clases para evitar sesgo hacia la clase mayoritaria.\n\n\n\nCode\n# Definir pipeline: estandarización + regresión logística\n#pipe = Pipeline([\n#    ('imputer', SimpleImputer(strategy='mean')),  # or 'median'\n#    ('scaler', StandardScaler()),\n#    ('logreg', LogisticRegression(solver='liblinear', class_weight='balanced',max_iter=1000))\n#])\n\npipe = Pipeline([\n    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n    (\"scaler\", StandardScaler()),\n    (\"regressor\", LinearRegression())\n])\n\n# Entrenar modelo\npipe.fit(X_train, y_train)\n\n\nPipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n                ('scaler', StandardScaler()),\n                ('regressor', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n                ('scaler', StandardScaler()),\n                ('regressor', LinearRegression())])PolynomialFeaturesPolynomialFeatures(include_bias=False)StandardScalerStandardScaler()LinearRegressionLinearRegression()"
  },
  {
    "objectID": "midterm.html#generación-de-predicciones.",
    "href": "midterm.html#generación-de-predicciones.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "4. Generación de predicciones.",
    "text": "4. Generación de predicciones.\n\n\nCode\ny_pred = pipe.predict(X_test)\ny_pred[:5]\n#y_prob = pipe.predict_proba(X_test)[:, 1]\n\n\narray([-0.03597007,  0.13780764,  0.20004948,  0.0872936 , -0.08477985])"
  },
  {
    "objectID": "midterm.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "href": "midterm.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "5. Evaluación del modelo con métricas apropiadas.",
    "text": "5. Evaluación del modelo con métricas apropiadas.\n\n\nCode\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n\nEl Mean Squared Error (MSE) mide cuánto se desvían en promedio las predicciones de los valores reales. Un MSE de 0.22 significa que el error cuadrático medio entre los valores reales del balance de masa y los predichos por el modelo es aproximadamente 0.22 metros, siendo muy alto y poco eficiente. Entonces el modelo no está logrando capturar bien la relación entre las variables explicativas y la variable dependiente.\n\n\nCode\nprint(\"Mean Squared Error (MSE):\", mse)\n\n\nMean Squared Error (MSE): 0.2258102663878953\n\n\nEl R² mide la proporción de la variabilidad de la variable objetivo que logra explicar el modelo. Un R² = 0.14 india que el modelo solo explica aproximadamente el 14% de la variación de los datos. Asi, las variables explicativas actuales (aspecto, pendiente, elevación, rugosidad, etc.) no son suficientes para explicar el comportamiento del balance de masa.\n\n\nCode\nprint(\"R² Score:\", r2)\n\n\nR² Score: 0.1359237069525524"
  },
  {
    "objectID": "midterm.html#visualizaciones-e-interpretación-de-resultados.",
    "href": "midterm.html#visualizaciones-e-interpretación-de-resultados.",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "6. Visualizaciones e interpretación de resultados.",
    "text": "6. Visualizaciones e interpretación de resultados.\nEn la matriz de comfusion Diagonal principal → predicciones correctas. Fuera de la diagonal → errores del modelo.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,6))\nplt.scatter(y_test, y_pred, alpha=0.7)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\nplt.xlabel(\"Valores Reales\")\nplt.ylabel(\"Valores Predichos\")\nplt.title(\"Regresión Lineal: Valores Reales vs Predichos\")\nplt.show()"
  },
  {
    "objectID": "midterm.html#qué-es-la-regresión-lineal-simple",
    "href": "midterm.html#qué-es-la-regresión-lineal-simple",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "",
    "text": "Es un método estadístico que se enfoca en analizar la relación lineal entre dos variables:\n\nUna variable independiente X (por ejemplo: horas de estudio)\nUna variable dependiente Y\n\nEl modelo tiene esta forma:\nY = b0 + b1*X\nDonde:\n\nb0: es la intersección (intercepto). Es el valor de Y cuando X = 0.\n\nb1: es la pendiente de la recta, y representa cuánto cambia Y por cada unidad que aumenta X.\n\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos, es decir que exista una minima diferencia entre el valor real y lo predicho. Este es el criterio de mínimos cuadrados."
  },
  {
    "objectID": "midterm.html#de-dónde-salen-las-fórmulas",
    "href": "midterm.html#de-dónde-salen-las-fórmulas",
    "title": "EVALUACION MIDTERM - Modelamiento de balance de masa",
    "section": "¿De dónde salen las fórmulas?",
    "text": "¿De dónde salen las fórmulas?\nQueremos encontrar una recta que se ajuste lo mejor posible a nuestros datos. Esa recta tiene la forma:\n$ _i = _0 + _1 x_i $\nDonde $ _i $ es el valor predicho, y $ y_i $ el valor real observado.\n\n¿Qué significa “mejor ajuste”?\nQueremos que los errores entre lo real y lo predicho sean lo más pequeños posible:\n$ _i = y_i - _i = y_i - (_0 + _1 x_i) $\nPara evitar que los errores se cancelen (positivos con negativos), los elevamos al cuadrado. Así, minimizamos el siguiente error total:\n$ = _{i=1}^{n} (y_i - _0 - _1 x_i)^2 $\nEste es el criterio de mínimos cuadrados.\n\n\n¿Cómo se minimiza?\nUsamos cálculo: derivamos la función de error respecto a los parámetros y resolvemos:\n\nDerivada respecto a $ _0 $:\n\n$ (y_i - _0 - _1 x_i)^2 = 0 $\n\nDerivada respecto a $ _1 $:\n\n$ (y_i - _0 - _1 x_i)^2 = 0 $\nEstas dos ecuaciones (llamadas ecuaciones normales) se resuelven para obtener:\n$ _1 = $ $ _0 = {y} - _1 {x} $"
  }
]